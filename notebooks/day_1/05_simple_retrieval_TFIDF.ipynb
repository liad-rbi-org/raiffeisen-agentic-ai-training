{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval with TF-IDF and BM25\n",
    "\n",
    "*Lexical search* is a type of search where a query is compared against a collection of text documents (as short as a sentence or as long as an entire article) by directly matching the words in the query. For example, given a query like \"What is a cat?\", you would look for documents that contains one or more of the words: \"What\", \"is\", \"a\", \"cat\". You can assign a score to each document based on how important each word is (by assigning a score to each word), and how many words are matched (e.g. by summing up the scores).\n",
    "\n",
    "Traditionally, retrieval was simply a keyword(s) search, aka a boolean search. The retrieval systme just looked for the existance of these words in the document. \n",
    "Soon enough, we learned that it's not enough. While all words were born equal, some are more equal than others.  \n",
    "\n",
    "TF-IDF is an algorithm that learns to reweight the words based on their frequencies: frequent words that appear often in the many documents get less weight, and rare words gets an increased weight.\n",
    "\n",
    "Let's see it in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c31f556f-018c-4997-9116-235c7f7530b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from typing import Iterator, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3cc1975-fa8c-47c5-a586-55481d838f98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Creating a Toy-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58eb93cb-93a1-4563-aed8-7dc0f8aba1ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Tech Stocks Rally as Investors Bet on Strong Quarterly Earnings\",\n",
    "    \"Global Markets Dip Amid Concerns Over Slowing Tech Sector Growth\",\n",
    "    \"Cryptocurrency Prices Surge Following Regulatory Clarity in Europe\",\n",
    "    \"Federal Reserve Hints at Future Rate Cuts Boosting Market Confidence\",\n",
    "    \"Oil Prices Fall as Supply Chain Disruptions Ease Worldwide\",\n",
    "    \"Major Bank Reports Record Profits Driven by Consumer Lending\",\n",
    "    \"Retail Stocks Drop After Weak Holiday Sales Forecast\",\n",
    "    \"Automakers Invest Heavily in Electric Vehicles to Stay Competitive\",\n",
    "    \"Investors Pull Back from Risky Assets Amid Inflation Fears\",\n",
    "    \"Fintech Startups Gain Momentum with New Digital Payment Solutions\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e13bc61a-ccf5-4f3d-aa6d-c04e76fefa74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Stop Word Removal and Stemming\n",
    "\n",
    "In real-world scenario, we must compromize between the model accuracy and its performance in terms of speed and space. One of the main factors to consuming space is the vocabulary size, the number of different tokens (types) we take into account.\n",
    "\n",
    "There are two main techniques to reduce the number of types:\n",
    "1. Removing stop words\n",
    "2. Stemming and Lemmatization\n",
    "\n",
    "Let's check them out:\n",
    "\n",
    "### Stop Word Removal\n",
    "Stop words are common words in a language (like ```\"the\"```, ```\"is\"```, ```\"and\"```) that appear frequently but carry little semantic meaning. Removing them reduces noise, decrease the number of tokens we must store, and therefore may improve the retrieval efficiency.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Original: ```\"The cat is sitting on the mat.\"```  \n",
    "After Stop Word Removal: ```\"cat sitting mat\"```\n",
    "\n",
    "### Stemming & Lemmatization\n",
    "[*Stemming*](https://www.geeksforgeeks.org/nlp/snowball-stemmer-nlp/) reduces words to their root form by chopping them abruptly, so that different variants of a word are treated as the same token. This helps in reducing the dimensionality, the number of different words we treat, as well as matching similar concepts and words, as they are all mapped to the same word.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Words: ```\"Consult\", \"Consultant\", \"Consulting\", \"Consultantative\", \"Consultants\"```  \n",
    "After Stemming: ```\"consult\"```\n",
    "\n",
    "*Lemmatization* reduces words to their base or dictionary form (aka lemma). Unlike stemming, which simply chops off the end of a word, lemmatization ensure the resulting lemma is a valid word. For example, \"better\" is lemmatized to \"good\" instead of a non-dictionary root word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize stemmer and stopwords\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "tfidf_vec = TfidfVectorizer(stop_words=\"english\")\n",
    "stop_words = set(tfidf_vec.get_stop_words())  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Task 1:\n",
    "\n",
    "Complete the preprocessing function in the code chunk below.\n",
    "\n",
    "The input of the function is a string of text.\n",
    "It returns a list of stemmed, non-stop words.\n",
    "\n",
    "1. Split the text into single words. (Hint: use the [```split()```](https://docs.python.org/3/library/stdtypes.html#str.split) function)\n",
    "2. For each word word check if it is a stop word using the ```stop_words``` set.\n",
    "3. Finally stem all the remaining words using [```stemmer.stem()```](https://www.nltk.org/api/nltk.stem.porter.html#nltk.stem.porter.PorterStemmer.stem).\n",
    "4. Return the resulting list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text: str) -> list[str]:\n",
    "    \"\"\"Preprocess the input text by tokenizing, removing stopwords, and stemming.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to preprocess.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: A list of preprocessed tokens.\n",
    "    \"\"\"\n",
    "    # Your code here:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess documents\n",
    "processed_docs = [\" \".join(preprocess(doc)) for doc in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "633470cc-81e2-46dc-ad80-b68774844743",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## TF-IDF: Term Frequency–Inverse Document Frequency\n",
    "\n",
    "**TF-IDF** is a numerical statistic that reflects how important a word is to a document within a collection (corpus).  \n",
    "It is widely used in information retrieval and text mining to rank documents by relevance.\n",
    "\n",
    "**1. Term Frequency (TF)**\n",
    "\n",
    "Measures how often a term $t$ appears in a document $d$.\n",
    "\n",
    "$$\n",
    "\\text{TF}(t, d) = \\frac{\\text{Number of times term } t \\text{ appears in } d}{\\text{Total number of terms in } d}\n",
    "$$\n",
    "\n",
    "**2. Inverse Document Frequency (IDF)**\n",
    "\n",
    "Measures how informative a term is, by counting the number of documents it appears in — rare terms get a higher score.\n",
    "\n",
    "$$\n",
    "\\text{IDF}(t) = \\log\\left(\\frac{\\text{Total number of documents}}{\\text{num of documents containing term t} + 1}\\right)\n",
    "$$\n",
    "\n",
    "(The $+1$ prevents division by zero.)\n",
    "\n",
    "**3. TF-IDF Score**\n",
    "\n",
    "$$\n",
    "\\text{TF-IDF}(t, d) = \\text{TF}(t, d) \\times \\text{IDF}(t)\n",
    "$$\n",
    "\n",
    "**Interpretation**\n",
    "\n",
    "* **High TF-IDF** → The term appears frequently in the document but rarely elsewhere → *important*.\n",
    "* **Low TF-IDF** → The term is common across documents or rare in the current one → *less informative*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TF-IDF Vectorization\n",
    "\n",
    "Now it is time to apply the TF-IDF vectorization to our preprocessed data. Fortunately, we don't have to code this ourselfs.  \n",
    "The vectorization is implemented for example in [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html).\n",
    "\n",
    "To perform retrieval, we preprocess and vectorize the query with the same TF-IDF model that we fit on the documents.  \n",
    "Then, a distance metric, such as [*cosine similarity*](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html), is used to measure the relevancy of each document, and find the best matching results.\n",
    "\n",
    "$$\\text{Cosine similarity}(\\theta) = \\frac{\\mathbf{A} \\cdot \\mathbf{B}}{\\|\\mathbf{A}\\| \\|\\mathbf{B}\\|}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7eaf566-21d4-4be4-a562-d67210d924a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create and fit a TfidfVectorizer over the document corpus\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db13673d-6a94-4b51-b47d-aa99bf411aaa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def retrieve_documents(qry: str) -> Iterator[Tuple[float, str]]:\n",
    "    \"\"\"Retrieve documents based on a TF-IDF.\n",
    "\n",
    "    Args:\n",
    "        qry (str): a query to search for\n",
    "\n",
    "    Yields:\n",
    "        Iterator[Tuple[float, str]]: a list of results and their matching score\n",
    "    \"\"\"\n",
    "    preprocessed_query = \" \".join(preprocess(qry))\n",
    "    print(f'Searching for: \"{preprocessed_query}\"')\n",
    "    query_vector = tfidf_vectorizer.transform([preprocessed_query])\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    cosine_sim = (tfidf_matrix @ query_vector.T).toarray().flatten()\n",
    "    tfidf_ranking = np.argsort(-cosine_sim)\n",
    "    for idx in tfidf_ranking:\n",
    "        if cosine_sim[idx] > 0:\n",
    "            yield cosine_sim[idx], documents[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval results using TF-IDF Ranking:\n",
      "Searching for: \"tech sector earn\"\n",
      "Score: 0.3899 | Doc: Tech Stocks Rally as Investors Bet on Strong Quarterly Earnings\n",
      "Score: 0.3653 | Doc: Global Markets Dip Amid Concerns Over Slowing Tech Sector Growth\n"
     ]
    }
   ],
   "source": [
    "query = \"Tech sector earnings\"\n",
    "# query = \"energy supply price drop\"\n",
    "# query = \"automobile sector investments\"\n",
    "\n",
    "print(\"Retrieval results using TF-IDF Ranking:\")\n",
    "for score, result in retrieve_documents(query):\n",
    "    print(f\"Score: {score:.4f} | Doc: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2:\n",
    "\n",
    "In the code above, experiment with different queries.\n",
    "Can you find weaknesses with TF-IDF vectorization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issues with TF-IDF\n",
    "\n",
    "- ?\n",
    "- ?\n",
    "- ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM-25\n",
    "\n",
    "BM-25 expands on TF-IDF and handles cases where long documents got priority and a higher score, due to their lexical richness. It adds 2 fraction variables over the TF and the IDF, allowing to control their influence on the scores.\n",
    "\n",
    "In this example, we will use [bm25s](https://github.com/xhluca/bm25s). A relatively newer version of BM25, which adds some more capabilities on top of the original algorithm, such as tokenization, and a more efficient score-matrix calculation. You can read more about it in [the paper](https://arxiv.org/abs/2407.03618).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bm25s\n",
    "import Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e420ff71d5af4e19afc3dc6519696fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e29b94ab6c4ada866ed8e4fa094476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stem Tokens:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415311bf3d404defab86c4663a1f86b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Count Tokens:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2b5875ed1a4ea6bcea88a7f36593ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Compute Scores:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stemmer = Stemmer.Stemmer(\"english\")\n",
    "\n",
    "# Tokenize the corpus and only keep the ids (faster and saves memory)\n",
    "corpus_tokens = bm25s.tokenize(documents, stopwords=\"en\", stemmer=stemmer)\n",
    "\n",
    "# Create the BM25 model and index the corpus\n",
    "retriever = bm25s.BM25()\n",
    "retriever.index(corpus_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents_bm25(qry: str, k: int = 2) -> Iterator[Tuple[float, int]]:\n",
    "    \"\"\"Retrieve documents using BM25.\n",
    "\n",
    "    Args:\n",
    "        qry (str): a query to search for\n",
    "        k (int): # of top results to retrieve\n",
    "\n",
    "    Yields:\n",
    "        Iterator[Tuple[float, str]]: a list of results and their matching score\n",
    "    \"\"\"\n",
    "    preprocessed_query = bm25s.tokenize(qry, stemmer=stemmer)\n",
    "    results, scores = retriever.retrieve(preprocessed_query, k=k)\n",
    "\n",
    "    for i in range(results.shape[1]):\n",
    "        score, doc = scores[0, i], results[0, i]\n",
    "        if score > 0:\n",
    "            yield score, doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval results using BM25 Ranking:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f525aef842b4bbda9491b2eadb6ae4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87dab11900f94cd19e777aa827c67002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stem Tokens:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1a80609b3e4cfab1f03cd3d4c674b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Retrieve:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1.4050 | Doc: Tech Stocks Rally as Investors Bet on Strong Quarterly Earnings\n",
      "Score: 1.2647 | Doc: Global Markets Dip Amid Concerns Over Slowing Tech Sector Growth\n"
     ]
    }
   ],
   "source": [
    "query = \"Tech sector earnings\"\n",
    "# query = \"energy supply price drop\"\n",
    "# query = \"automobile sector investments\"\n",
    "\n",
    "print(\"Retrieval results using BM25 Ranking:\")\n",
    "for score, result in retrieve_documents_bm25(query, 3):\n",
    "    print(f\"Score: {score:.4f} | Doc: {documents[result]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Larger dataset\n",
    "Let's make it real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_retrieval_corpus = pd.read_parquet(\"../../data/financial_retrieval_corpus.parquet\")\n",
    "financial_retrieval_queries = pd.read_parquet(\"../../data/financial_retrieval_queries.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a larger corpus. Some of these documents are quite long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NVIDIA Announces Financial Results for Second ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2 Fiscal 2024 Summary GAAP ($ in millions, ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Outlook NVIDIA’s outlook for the third quarter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gaming Second-quarter revenue was $2.49 billio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Automotive Second-quarter revenue was $253 mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stock futures edged lower on Thursday morning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Japan’s September trade balance swings into su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Here are some of the tickers on my radar for T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\t2022 12/31/22\\t2021 12/31/21\\t2020 12/31/20\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Nokia said it would cut up to 14,000 jobs as p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The stock was trading at $14 per share</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>On Thursday, the stock closed at $12 per share...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The loan will commence on January 15, 2014, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bryan was 37 years old in 2012.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The executive received a salary of $425,000 la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The invoice was issued on January 12, with not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>On Tuesday, there were 1,000 shares that trade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>According to the terms of the lease, the rent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>According to the offer letter, the base salary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Myra is 23 years old. Ashish is 27 years old. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Elizabeth is 35 years old.  John is 47 years old.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Milk - $4.50.  Cheese - $6.25. Chocolate - $3....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Stock futures were higher Wednesday as traders...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The fund currently hold the following position...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The company has received orders in the last 30...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content\n",
       "0   NVIDIA Announces Financial Results for Second ...\n",
       "1   Q2 Fiscal 2024 Summary GAAP ($ in millions, ex...\n",
       "2   Outlook NVIDIA’s outlook for the third quarter...\n",
       "3   Gaming Second-quarter revenue was $2.49 billio...\n",
       "4   Automotive Second-quarter revenue was $253 mil...\n",
       "5   Stock futures edged lower on Thursday morning ...\n",
       "6   Japan’s September trade balance swings into su...\n",
       "7   Here are some of the tickers on my radar for T...\n",
       "8   \\t2022 12/31/22\\t2021 12/31/21\\t2020 12/31/20\\...\n",
       "9   Nokia said it would cut up to 14,000 jobs as p...\n",
       "10             The stock was trading at $14 per share\n",
       "11  On Thursday, the stock closed at $12 per share...\n",
       "12  The loan will commence on January 15, 2014, an...\n",
       "13                    Bryan was 37 years old in 2012.\n",
       "14  The executive received a salary of $425,000 la...\n",
       "15  The invoice was issued on January 12, with not...\n",
       "16  On Tuesday, there were 1,000 shares that trade...\n",
       "17  According to the terms of the lease, the rent ...\n",
       "18  According to the offer letter, the base salary...\n",
       "19  Myra is 23 years old. Ashish is 27 years old. ...\n",
       "20  Elizabeth is 35 years old.  John is 47 years old.\n",
       "21  Milk - $4.50.  Cheese - $6.25. Chocolate - $3....\n",
       "22  Stock futures were higher Wednesday as traders...\n",
       "23  The fund currently hold the following position...\n",
       "24  The company has received orders in the last 30..."
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_retrieval_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are some queries for this dataset. For each query, we know exactly what the expected answer is, and in which document number (`contenet_index`) it should be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>answer</th>\n",
       "      <th>content_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What was the increase in revenue from the prev...</td>\n",
       "      <td>Up 101%</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What was the revenue in second quarter?</td>\n",
       "      <td>$13.51 billion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many shares were repurchased in second qua...</td>\n",
       "      <td>7.5 million shares</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who is the CEO of Nvidia?</td>\n",
       "      <td>Jensen Huang</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What was the percentage increase in data cente...</td>\n",
       "      <td>Up 141% from Q1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Which stock index increased by the fewest poin...</td>\n",
       "      <td>Dow Jones Industrial futures, up 23 points.</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Which stock index increased by the highest per...</td>\n",
       "      <td>S&amp;P 500 futures futures, up 1.2%.</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Which stock has the highest price - (A) River ...</td>\n",
       "      <td>(A) River Industries</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>If Smithson stock increases by $2, what is the...</td>\n",
       "      <td>(C) $21</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Which order has the smallest value - (A) PO 35...</td>\n",
       "      <td>(B) PO 1993</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                query  \\\n",
       "0   What was the increase in revenue from the prev...   \n",
       "1             What was the revenue in second quarter?   \n",
       "2   How many shares were repurchased in second qua...   \n",
       "3                           Who is the CEO of Nvidia?   \n",
       "4   What was the percentage increase in data cente...   \n",
       "..                                                ...   \n",
       "95  Which stock index increased by the fewest poin...   \n",
       "96  Which stock index increased by the highest per...   \n",
       "97  Which stock has the highest price - (A) River ...   \n",
       "98  If Smithson stock increases by $2, what is the...   \n",
       "99  Which order has the smallest value - (A) PO 35...   \n",
       "\n",
       "                                         answer  content_index  \n",
       "0                                       Up 101%              0  \n",
       "1                                $13.51 billion              0  \n",
       "2                            7.5 million shares              0  \n",
       "3                                  Jensen Huang              0  \n",
       "4                               Up 141% from Q1              0  \n",
       "..                                          ...            ...  \n",
       "95  Dow Jones Industrial futures, up 23 points.             22  \n",
       "96            S&P 500 futures futures, up 1.2%.             22  \n",
       "97                         (A) River Industries             23  \n",
       "98                                      (C) $21             23  \n",
       "99                                  (B) PO 1993             24  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_retrieval_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "It's your turn now to evaluate how well *BM25s* work on this dataset.  \n",
    "Tokenize the dataset, and run the queries. Evaluate how often the correct document was retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### YOUR CODE HERE ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_simple_retreival_TFIDF_BM25",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
